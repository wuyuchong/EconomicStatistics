---
documentclass: ctexart
output:
  rticles::ctex:
    fig_caption: yes
    number_sections: yes
    template: template.tex
  word_document: default
classoption: "hyperref,"
geometry: margin=1in
csl: chinese-gb7714-2005-numeric.csl
bibliography: reference.bib
header-includes:
   - \usepackage{graphicx}
   - \usepackage{float}
logo: "cufe.jpg"
---

```{r setup, include=FALSE, message=FALSE}
knitr::opts_chunk$set(fig.pos = 'H', echo = FALSE, warning = FALSE, message = FALSE)
library(knitr)
library(tidyverse)
library(caret)
library(kernlab)
library(pROC)
# base_family = 'STXihei'
```

# 摘要{-}

---

> 待完善：企业员工离职的案例研究

---

\newpage

\tableofcontents

# 背景

随着市场化和国际化的不断推行，行业的更迭越来越快，企业间的竞争变得越来越激烈，人力资源的流动也变得越来越快。可以说，人力资源的流动是一家公司、整个社会不可或缺也不可避免的一部分，一方面它使得人力资源的分配更高效；然而，另一方面，它也带来了一些摩擦性失业。

从社会科学的角度，对人力资源流动的合理预判有利于调整就业市场，尽可能地减小摩擦性失业。

从人才就业服务中心的角度，将合适的人放置于合适的企业、匹配的岗位是其工作的核心。

从企业的角度，由于企业的核心技术和运营业务被优秀的人才掌握，公司希望尽量避免自己所器重的员工为了更好的就业机会而主动离职，避免公司竞争力降低的同时竞争对手掌握主动权；同时，对于非核心的员工，公司则希望能够预判员工的离职，以降低离职率，减轻员工离职对公司正常经营活动的影响，节省公司新招聘员工的成本。

大部分企业都会设立人事部专门管理人力资源问题，企业有着招聘员工需要付出一定的成本，而员工入职后的培训和磨合也需要不小的费用。能够胜任工作的优秀员工的离职对于企业来说是不小的损失。所以，人员的频繁离职是人力资源部极为重视的问题之一。

分析一个企业甚至是整个社会普遍的人力资源状况并从中找出员工离职问题的原因，找到合适的问题解决方案加以实施，

引起员工离职的原因有很多，员工的薪资、满意度、工龄等等都是重要因素，通过描述性统计，我们能大致刻画出主动离职和被解雇员工的群体画像，得到一些结论。但是相较于得出群体结论，企业或是人才服务中心更加关注精确到每位员工上，从每位员工自身的角度，离职的原因又有很强的自身独特性，准确地预测出每位员工是否处于离职的边缘较难。

# 文献综述

国内学者赵西萍、刘玲和张长征在问卷调查的基础上，采用因子分析法和多元相关分析法提取主要因子，以对员工工作态度进行测度，提取引起员工离职倾向的关键因素。 @赵西萍2003A 

国内学者张紫君使用梯度提升分类树（GBDT）算法构建模型预测企业员工离职，采用 smote 算法对样本进行倾斜处理、采取网格搜索法模型的调优、使用混淆矩阵和 ROC 曲线进行评价模型、运用梯度提升分类树决定重要特征。 @张紫君2018企业员工的离职预测模型

国内学者杨喆麟作为管理者和参与人力资源规划的研究人员以案例分析的形式，以星巴克公司驻中国部作为案例研究对象，研究招聘培训以及薪酬福利的特点、提高员工工作积极性的方法；并进一步对星巴克员工离职问题提出优化措施找到切实可行的优化策略，以降低离职率、提高企业竞争优势。 @杨喆麟2017星巴克

国内学者张梓嫣用问卷调查的方法对 BJM 公司进行案例分析，深入剖析了 BJM 公司留才策略的详细计划和执行现状，同时对其他的影视公司乃至整个影视行业如何缓解新员工频繁离职具有很高的参考价值。
@张梓嫣2019BJM

在我们的研究中，我们吸收了几位学者优秀的研究成果，并在他们的基础上继续加以研究创新，通过案例研究的方式，对数据进行分析和处理，建立模型对 XXXXX 进行预测，选用多种机器学习模型进行模型比较，为 XXXX 提供更多的评判思路。但与此同时，研究并不局限于一个案例，而是具有普适性，在实际应用过程中能够有效地推广到不同企业，为社会的决策提供参考依据.......


# 目的

1. 从企业角度：通过对员工是否将离职进行预测，可以为企业提前找到潜在的离职员工，通过一定措施留住企业并不想解雇的员工，以减小离职率。
1. 从社会角度：利用大数据，通过对社区人员的信息统计，对数据进行脱敏处理后，可以预测人力资源流动、监测摩擦性失业指标，为政策决策提供依据，达到减小社会失业率的目的。

在实际应用中，我们并不局限于此数据集，此研究为离职的预测提供思路，在应用时可以加以调整，使用更大维度的数据集，在分布计算环境下进行学习预测。

结合心理学探究员工的离职原因，结合管理学制定针对员工频繁离职的管理和激励制度，结合社会学培养良好的企业文化氛围。

# 待处理

---

应用机器学习算法探索导致离职的决定性因素及其影响关系，以推断出哪些员工最有离职的倾向,企业就可以提前作出应对策略,尽量的避免这种事情的发生,同时调整公司的用人制度和政策,如果员工离职纯属个人原因,公司应该提前准备后备人才,以便随时可以顶岗,公司不会因个别人才的流失而受到难以补救的损失。从数据中看到更深的层次,挖掘出内在的问题,从而提前采取措施,可以避免造成更多的损失。

为企业做出预警的同时辅助人力资源团队进行关键的干预工作

研究了离职与这些影响因素的关系,并对用人单位做出了一些简单的总结和建议。

结合需求层次理论、双因素理论、公平理论和职业生涯理论等进行探究；并分别从招聘方面、培训方面、激励方面、薪酬方面、工作方面和职业规划方面探究影响员工离职的因素。离职的原因,包括个人发展因素、公司制度及文化因素、入职培训因素、工作关系因素和工作内容与环境因素五个方面;然后,针对BJM公司新员工离职问题提出对策,包括对策制定的目标和原则、确定对策制定的总体思路以及从加强招聘管理、建立有效的沟通机制、优化岗位设计和制定科学的激励制度四个方面提出了相应的对策;最后,结合对策制定,提出了BJM公司新员工离职管理的保障措施,具体包括加强对新员工离职管理的组织领导、重视人力资源规划与合理配置、重塑组织文化三个方面。

本研究的研究结论为:(1)BJM公司新员工离职的主要影响因素为组织因素,其中四大主要离职影响因素为:不适应复杂的公司文化、对公司培训体系不满、缺乏公平的考核和激励制度、与领导相处不融洽。(2)新员工对于公司员工管理方面的意见主要集中在:上下级沟通不畅,上级关怀不够、内部缺乏公平考核制度和激励政策、新员工的融入难,主要体现在新员工管理、培训等方面、对员工缺乏有效的职业发展规划以及没有留住新员工的有效措施等。(3)针对BJM公司新员工离职原因调查结果,本研究制定了BJM公司新员工离职的对策,提出了具体的保障措施,在一定程度上能够有针对性地改善公司的人力资源管理问题,提高员工的满意度,降低公司新员工的离职率。其中,制定了BJM公司新员工离职的对策包括:加强公司新员工招聘管理机制、建立公司新员工有效的沟通机制、提高新员工岗位设计水平。新员工离职率降低对策的保障措施包括:其一,加强对新员工离职管理的组织领导,具体从提高管理层的重视程度和改善领导风格两点展开;其二,重视人力资源规划与合理配置,具体从提供足够的职业发展空间和建立科学的培训体系两点展开;其三,重塑组织文化,具体从经营公司文化环境建设、抓好公司文化的“软实力”建设和落实人文关怀文化建设三点展开。

本研究有助于BJM公司充分认识到新员工离职问题的重要性,能促使其及时准确地发觉管理过程中可能存在的隐患,并为其结合自身发展战略和实际情况,优化人力资源管理机制,实施相关保障措施以实现最大程度地降低可能产生的一系列经济及其他方面的损失提供较好的理论支持和指导价值。对于那些同样面临新员工频繁离职问题的影视公司而言,本研究的结论可以起到“预防和免疫”的作用,能促使其及时做出战略上的调整,将可能产生的损失降到最低,减少新员工流失对于公司业务所造成的负面影响。

> 查重

---

# 数据集说明

我们使用一个公开的数据集 ^[数据来源: https://rpubs.com/rhuebner/HRCodebook-13] ，它有 35 个变量，310 个观测。 ^[模型的变量取值和分布见附录]

```{r}
dat = read.csv("data.csv", header = TRUE)
dat = dat[2:ncol(dat)]

dat_complete = dat %>% 
  mutate(Terminate = 0)
dat_complete$Terminate[which(dat_complete$EmploymentStatus %in% c("Voluntarily Terminated", "Terminated for Cause"))] = 1
dat_complete$Terminate = as.factor(dat_complete$Terminate)

training = dat_complete
dat_complete = dat_complete %>% 
  filter(Department != "Executive Office")
```

# 数据预处理

1. 为了保护员工的个人隐私，我们对数据进行了脱敏处理。
1. 建模前，我们对原始数据进行了相关预处理，包括将数据中的缺失值、重复值、异常值的处理，对每个变量的数据分别进行标准化。对分类变量，我们采用因子化编码的处理方法，选定一个因子水平作为基准水平，将其余的因子水平拆分为各个虚拟变量 (Dummy Variables) 。
1. 我们将**主动辞职**和**被迫离职**的标记为离职，与**在职**相对应，生成一个虚拟变量。

# 描述分析

## 时薪（美元）

```{r fig.align="center", fig.cap="离职与在职两类员工日薪分布密度图（红色代表离职）", out.width="80%"}
ggplot(dat_complete, aes(x = PayRate, fill = Terminate)) +
  geom_density(alpha = 0.3) + 
  theme_minimal() +
  scale_fill_manual(values = c("#037418", "darkred"))
```

离职的员工与在职的员工的有着相似的薪资分布情况，员工的时薪在 20 - 25 美元和 45 - 60 美元之间较为集中。但有所不同的是，离职的员工集中于 20 - 25 美元的比例更大，而集中于 45 - 60 美元的比例更小。这说明薪资过低的确是离职的一个较为重要的理由之一。

```{r fig.align="center", fig.cap="不同性别员工日薪分布密度图（蓝色代表已婚）", out.width="80%"}
ggplot(dat_complete, aes(x = Sex, y = PayRate, fill = as.factor(MarriedID))) +
  geom_violin(alpha = 0.3) + 
  theme_minimal() +
  labs(fill = "Married")
```

女性相比男性，时薪在 20 - 25 美元的低水平处聚集更加明显。

已婚员工群体相对于未婚员工群体，最低薪资相对更高一些，低收入范围的平均工资更高一些，且中等收入范围的员工比例更多。考虑到婚姻状况与年龄强相关，我们认为这很有可能是由员工的工作经验所带来的影响。

## 参与感

```{r fig.align="center", fig.cap="离职与在职两类不同部门员工参与感箱线图（红色代表离职）", out.width="80%"}
dat_complete %>% 
  ggplot(mapping = aes(x = reorder(Department, EngagementSurvey), y = EngagementSurvey, fill = Terminate)) +
    geom_boxplot(alpha = 0.5) +
    labs(x = "Department", y = "Rate for Engagement", fill = "Terminate") +
    theme_minimal() +
    scale_fill_manual(values = c("#037418", "darkred"))
```

技术和销售部门员工的参与感不如生产和行政部门。对于 IT 和软件开发部门，离职者的参与感比在职者弱，他们离职的原因之一是没有获得足够的归属感和价值感。而对于销售和生产部门，离职着的参与感比在职者更强，工作太过繁忙可能是促成他们离职的一大原因。而对于行政岗位，没有足够的参与感往往意味着地位不足，可能收到部门的排挤和边缘化，促成了人员的离职。

## 绩效

```{r fig.align="center", fig.cap="不同任职状况的员工绩效（红色代表离职）", out.width="80%"}
ggplot(dat_complete, aes(x = EmploymentStatus, fill = PerformanceScore)) +
  geom_bar(stat = "count", position = "fill") +
  theme_minimal() +
  labs(y = "count") + 
  coord_flip()
```

1. 在职员工的绩效普遍都在优秀和良好两档
1. 自愿离职的员工绩效优秀的比例小一些
1. 被解雇的员工绩效为 “需要提高” 的比例非常高，同时解雇前已经被列入 “解雇缓冲” 的比例远高于在职和自愿离职的员工

可见绩效表现不好、不适应工作是员工自愿离职或被解雇的重要原因之一。

# 建立解释模型

## 拟合

因为 logit 模型相对简单，求解速度快，且具有较强的可解释性，故我们使用 logit 模型对样本进行拟合。 ^[模型详细见附录]

我们将**离职**作为响应变量，选取的自变量有：

1. 性别
1. 婚姻状况：包括离婚、已婚、分居、未婚、配偶去世
1. 所在部门：包括行政部、总裁办公室、IT部门、产品部门、销售部门、软件工程部门
1. 绩效：超过、符合要求、需要提高、进入淘汰流程
1. 员工参与感：1-5 员工自行打分
1. 员工满意度：1-5 员工自行打分
1. 在过去的 6 个月内员工进行的特殊项目个数
1. 时薪（美元）

对于连续型变量，我们直接将它们加入模型之中；对于因子型变量，我们将它们转换成为隐变量。

```{r}
logit2 = glm(Terminate ~ Sex + MaritalDesc + Department + PerformanceScore + EngagementSurvey + EmpSatisfaction + SpecialProjectsCount + PayRate, data = dat_complete, family = binomial(link = "logit"))
logit2_sum = summary(logit2)
kable(logit2_sum$coefficients, caption = "Logit回归系数表", digit = 2)
```

在 Z 检验的 p 值中，在众多的因素之中，只有**婚姻状况**中的“分居”和“单身”，和**绩效表现**中的“有待提高”是统计上显著的。 ^[在 95% 置信区间下] 

- 分居者和单身者的离职概率都显著较低，这可能与他们在经济上的独立性有关。分居者和单身者相比结婚合居者，在经济上不太依赖他人，有稳定的收入对他们来说更为重要，离职率自然较低一些。
- 绩效表现较差的员工离职概率也较高，这一方面可能是由于员工自身品质不佳或能力不足造成的不胜任岗位；另一方面也可能是员工与企业的文化不契合，对于工作内容或是上级不适应不喜欢；还有可能是企业处于末位淘汰制度或是效益不好，而对员工进行主动辞退的操作。

同时，**部门**中的销售部门、**绩效表现**中的“良好”和**特殊项目数量**这三个变量也有一定的显著性。 ^[在 90% 置信区间下] 

- 相比技术部门，销售部门人员离职概率较低，这可能与销售人员在行业内专一产品方向所积累的经验和人脉有关。相比 IT 技术人员，销售人员的人脉可能更加局限于某一细分行业，跳槽的机会较少；而且，随着经验和人脉的积累，销售部门人员在企业内逐渐拿到更多的销售提成，对于企业的价值越来越大，企业对资深销售人员的待遇逐渐抬升；反过来，销售人员也一定程度上依赖着企业的平台，跳槽对于销售人员的不确定性较高。
- 特殊项目的数量与离职率负相关，从心理学的角度，这与员工的成就感和价值感有关，由于他们的工作不仅局限于日常工作，其它的项目推进让他们有更多的参与感和成就感，进而增强了对企业的归属感；同时，反过来说，参加特殊项目多的员工很可能本身就是为企业器重的核心人员，他们本身待遇和地位都较高，离职倾向不明显。


## 预测

我们对样本进行随机抽样，划分为 75% 的训练集和 25% 的测试集（验证集）。

```{r}
set.seed(1)
inTraining <- createDataPartition(dat_complete$Terminate, p = .75, list = FALSE)
train <- dat_complete[inTraining,]
test <- dat_complete[-inTraining,]
```

```{r fig.align="center", fig.cap="预测的离职概率值（红色代表已知为逾期）", out.width="80%"}
logit3 = glm(Terminate ~ Sex + MaritalDesc + Department + PerformanceScore + EngagementSurvey + EmpSatisfaction + SpecialProjectsCount + PayRate, data = train, family = binomial(link = "logit"))
probability = predict(logit3, test, type = "response")
distribution = as.data.frame(probability)
distribution = cbind(distribution, group = test$Terminate)
ggplot(distribution, aes(x = probability, fill = group)) +
  geom_density(alpha = 0.3) + 
  theme_minimal() +
  scale_fill_manual(values = c("#037418", "darkred"))

testPred = probability
testPred[testPred > 0.5] = 1
testPred[testPred <= 0.5] = 0
testPred = as.factor(testPred)
```

从预测概率分布图，对于真实情况为在职的员工，我们预测出的离职概率值的分布是有偏的；比较之下，对于真实情况为在职的员工，我们预测出的离职概率值的分布则显得较为均匀。

对于真实情况为离职的员工，大部分得到的预测离职概率值的确都比较高。但对于真实情况为在职的员工，虽然大部分得到的预测离职概率较低，但仍然有相当一部分的预测离职概率值超过 50%。

为此，我们猜想：**我们的模型将没有离职倾向的员工错预测为离职的概率较低，但是较难识别出可能离职的员工。**

为了验证我们的猜想，我们使用混淆矩阵来计算预测模型的灵敏度和特异度。

## 混淆矩阵与验证结果

我们将预测概率大于 50% 的判定为离职。

灵敏度（Sensitivity）

$$\text{灵敏度} = \frac{\text{正确判定为“离职”的样本数量}}{\text{观测到的“离职”的样本数量}}$$

特异度（Specificity）

$$\text{特异度} = \frac{\text{正确判定为“在职”的样本数量}}{\text{观测到的“在职”的样本数量}}$$

假离职率

$$\text{假离职率} = 1 - \text{观测到的“在职”的样本数量}$$

```{r}
confusion = confusionMatrix(data = testPred,
                reference = test$Terminate,
                positive = "1")
kable(as.data.frame(confusion$table), caption = "混淆矩阵表")
```

```{r}
table = as.data.frame(confusion$overall)
names(table) = c("指标值")
table = t(table)
rownames(table) = NULL
kable(table, caption = "验证结果表", digit = 3)
```

可以看到：使用简单的 Logit 回归模型进行预测的准确率大致为: 59.2% ^[95% CI : (0.5131, 0.7394)] ，置信区间 XXX ，并不算高，甚至低于无信息准确率（即不经预测直接将所有员工归为在职）。但这并不代表模型是无用的。
^[事实上，在预测一些有偏分布的小概率事件时，模型准确率通常会低于无信息准确率。]

```{r}
table = as.data.frame(confusion$byClass[1:5])
names(table) = c("指标值")
table = t(table)
kable(table, caption = "灵敏度和特异度等指标表", digit = 3)
```

从灵敏度和特异度来看：40% 的有离职倾向的员工会被模型成功捕捉到；对于模型捕捉到的员工，只有 13.7% 的误判率。

这验证了我们的猜测：**对于真正离职的员工，模型不一定能准确预测到；不过模型预测认为有离职倾向的员工在绝大部分情况下的确会发生离职**

在模型准确度稳定的前提下，需要我们在灵敏度和特异度之间有所取舍。实际上，由于样本会更多的被认为是“发生”，所以灵敏度上升会使特异度下降。这二者之间的潜在利弊的权衡是合理的，因为不同类型的错误对应不同的惩罚。在对员工是否会离职做识别和预测的时候我们通常关注特异度，只要模型能够捕捉到部分可能离职的员工，模型对于企业人力资源部门或是劳动力服务中心还是有很强的实用性的。

## 接受者操作特征（ROC）曲线

为了在灵敏度和特异度二者间权衡，我们使用接受者操作特征（ROC）曲线。

ROC曲线 (Altman 和 Bland 1994; Brown 和 Davis 2006; Fawcett 2006) @Altman1994Diagnostic @Brown2006Receiver @Fawcett2006An 是一种常用方法, 在给定连续数据点集合的情况下，确定有效阈值，使阈值以上的值表示特定事件。ROC 曲线可以用来决定分类概率的阈值。

```{r fig.align="center", fig.cap="Logit 模型的 ROC 曲线", out.width="60%"}
rocCurve = roc(response = test$Terminate,
               predictor = probability,
               levels = rev(levels(test$Terminate)),
               plot = TRUE,
               print.thres=TRUE, print.auc=TRUE)
```

前文计算灵敏度和特异度时，我们默认 50% 概率阈值。为了捕获更多真阳性样本的方式提高灵敏度，我们可以通过降低阈值的方法，将灵敏度从 40% 提高到了 96% ，特异度从 86.3% 降低到了 35.3%。

也就是说，降低阈值有利于我们识别出更多有离职倾向的员工，但同时也会使误判的几率上升。

在实际操作中，我们可以通过**确定不同的阈值来达到不同的效果**，例如：

1. 在进行交易风控、信用卡降额的自动化系统构建时，通过确定较高的阈值以提高特异度，避免错判。
2. 在进行逾期自动化预测以便于进一步调查时，通过降低阈值的方式提高灵敏度，以检测出更多潜在逾期持卡人。
3. 通过平衡错判的成本与查漏的损失，确定适中的阈值以谋求商业利益最大化。

# 预测模型的选择

## 抽样、训练与评价指标

```{r}
set.seed(1)
fitControl <- trainControl(## 10-fold CV
                           method = "repeatedcv",
                           number = 10,
                           ## repeated ten times
                           repeats = 5)
```

由于数据集样本量过大，难以完成较为复杂的模型求解。 ^[由于条件所限，本研究小组只有单台计算机的算力。在有分布式计算的环境下，可能不需要此步操作。] 我们从总样本中随机抽取 1% 的数据用于各种模型的训练和验证。

我们使用10折交叉验证，重复5次的方法进行重抽样。

我们使用 Kappa 和准确率作为模型的评价指标。

Kappa 统计量（Cohen 1960） @Cohen1960A 最初是一个用来评估两个估价者评估结果的一致性，同时也考虑到了由偶然情况引起的准确性误差。

$$\mathrm{Kappa}=\frac{O-E}{1-E}$$

在上面的公式里，O代表的是准确性，E则代表着根据混淆矩阵边缘计数得出的期望准确性。0值意味着观测类和预测类是不同的，1值表示模型的预测与观测类是相同的，这个统计的量取值在-1和1之间。虽然绝对值大的负数值在模型预测中出现的很少，但负数代表实际和预测值是相反的。总精确度在各类分布相同的时候与 Kappa是成比例的。Kappa值在0.30到0.50间代表着合理的一致性，这要依具体情况而定。（Agresti 2002）

## Logit 回归

```{r}
set.seed(1)
logit <- train(Terminate ~ Sex + MaritalDesc + Department + PerformanceScore + EngagementSurvey + EmpSatisfaction + SpecialProjectsCount + PayRate, data = training, 
                 method = "glm", 
                 trControl = fitControl)
table = logit$results
rownames(table) = NULL
kable(table, caption = "在重抽样下 Logit 模型的表现", digits = 3)
```

Logit 是一个受到非常广泛应用的模型，它十分简单、计算速度非常快，而且具有很强的可解释性。虽然 Logit 模型已经有很好的预测分类能力，但如果我们仅仅关注这一预测准确性这一指标，可能还有其它模型有更佳的表现。

## 线性判别分析（LDA）

Fisher（1936）@fisher36lda 和 Welch（1939）@WELCH1939 分析了获得最优判别准则的方式。

由贝叶斯法则：

$$
\operatorname{Pr}\left[Y=C_{\ell} | X\right]=\frac{\operatorname{Pr}\left[Y=C_{\ell}\right] \operatorname{Pr}\left[X | Y=C_{\ell}\right]}{\sum_{\ell=1}^{C} \operatorname{Pr}\left[Y=C_{\ell}\right] \operatorname{Pr}\left[X | Y=C_{\ell}\right]}
$$

对于二分类问题，如果：

$$
\operatorname{Pr}\left[Y=C_{1}\right] \operatorname{Pr}\left[X | Y=C_{1}\right]>\operatorname{Pr}\left[Y=C_{2}\right] \operatorname{Pr}\left[X | Y=C_{2}\right]
$$

我们就将 X 分入类别1，否则分入类别2。

为了计算 $\operatorname{Pr}\left[X | Y=C_{\ell}\right]$，我们假设预测变量服从多元正态分布，分布的两个参数为：多维均值向量 $\boldsymbol{\mu}_{\ell}$ 和协方差矩阵 $\boldsymbol{\Sigma}_{\ell}$，假设不同组的均值向量不同且协方差相同，用每一类观测样本均值 $\bar{x}_{\ell}$ 估计 $\boldsymbol{\mu}_{\ell}$，用样本协方差 $\boldsymbol{S}$ 估计理论协方差矩阵 $\boldsymbol{\Sigma}$，将样本观测 $\mu$ 代入 $X$，第 $\ell$ 组的线性判别函数为：

$$
X^{\prime} \boldsymbol{\Sigma}^{-1} \boldsymbol{\mu}_{\ell}-0.5 \boldsymbol{\mu}_{\ell}^{\prime} \boldsymbol{\Sigma}^{-1} \boldsymbol{\mu}_{\ell}+\log \left(\operatorname{Pr}\left[Y=C_{\ell}\right]\right)
$$

由于我们的分类只有两类，所以只有一个判别向量，不需要优化判别向量的数目，即不需要模型调优，计算速度较快。

当我们仔细观察线性判别函数时,我们会发现 Fisher 的线性判别方法有两点缺陷：

1. 而且，由于线性判别分析的数学构造，随着预测变量数目的增加，预测的类别概率越来越接近0和1。这意味这，在我们的数据集下，由于变量较多，如前文所述的调整概率阈值的方法可能有效性会降低。这在单纯分类**逾期**和**信用良好**的持卡人时可能并不是问题，但在需要进一步平衡灵敏度和特异度以达到更好效果时将很难进行。

2. 由于线性判别分析的结果取决于协方差矩阵的逆，且只有当这个矩阵可逆时才存在唯一解。这意味着样本量要大于变量个数 ^[一般要求数据集含有至少预测变量5——10倍的样本]，且变量必须尽量相互独立。而在我们的数据集中，变量之间有很强的多重共线性，这在一定程度上会降低预测的准确性。

```{r}
set.seed(1)
lda <- train(Terminate ~ Sex + MaritalDesc + Department + PerformanceScore + EngagementSurvey + EmpSatisfaction + SpecialProjectsCount + PayRate, data = training, 
                 method = "lda", 
                 trControl = fitControl,
               preProc = c("center", "scale"))
table = lda$results
rownames(table) = NULL
kable(table, caption = "在重抽样下 LDA 模型的表现", digits = 3)
```

```{r fig.align="center", fig.cap="在重抽样下 LDA 模型的准确率分布", out.width="50%"}
trellis.par.set(caretTheme())
densityplot(lda, pch = "|")
```

## 偏最小二乘判别分析（PLSDA）

由于 LDA 不太适合多重共线性的变量，我们可以试着使用主成分分析压缩变量空间的维度，但 PCA 可能无法识别能将样本分类的较好变量组合，且由于没有涉及被解释变量的分类信息（无监督），很难通过 PCA 找到一个最优化的分类预测。

所以，我们使用偏最小二乘判别分析来进行分类。Berntsson 和 Wold（1986） @Peder1986Comparison 将偏最小二乘应用在了问题中，起名为偏最小二乘判别分析（PLSDA）。尽管 Liu 和 Rayens（2007） @Liu2007PLS 指出，在降维非必须且建模目的时分类的时候，LDA 一定优于 PLS，但我们希望在降维之后，PLS 的表现能超过 LDA。

我们只使用前十个 PLS 成分

```{r}
set.seed(1)
plsda <- train(Terminate ~ Sex + MaritalDesc + Department + PerformanceScore + EngagementSurvey + EmpSatisfaction + SpecialProjectsCount + PayRate, data = training, 
                 method = "pls", 
                 trControl = fitControl,
               tuneGrid = expand.grid(.ncomp = 1:10))
table = plsda$results
rownames(table) = NULL
kable(table, caption = "在重抽样下 PLSDA 模型的表现", digits = 3)
```

```{r fig.align="center", fig.cap="Kappa 指标和准确率随主成分个数的变化", out.width="49%", fig.show='hold'}
trellis.par.set(caretTheme())
plot(plsda, metric = "Kappa")
plot(plsda)
```

我们可以看到 Kappa 指标随主成分个数的增多而先上升，后有所下降；准确率指标随着主成分个数的增加而先下降、后上升到顶峰、再下降。可见，在此模型中，选取前 8 个主成分不管是 Kappa 还是准确率指标都是最佳状态。

```{r fig.align="center", fig.cap="变量重要程度", out.width="80%"}
plsImp = varImp(plsda, scale = FALSE)
table = data.frame(variables = rownames(plsImp$importance), importence = plsImp$importance$Overall)
ggplot(table, aes(x = reorder(variables, importence), y = importence)) +
  geom_col() +
  theme_minimal() +
  coord_flip() +
  labs(x = "variables")
```

我们将变量按照其在 PLSDA 模型中的重要性进行排序：排在前三名的是“婚姻状况中的独居”、“绩效表现中的较差一类”和“婚姻状况中的已婚”。这三个变量对于不同部门、不同工作内容、不同工作地位的员工具有较强的普适性。属于对员工个人的刻画，对于预测员工是否离职较为重要。

而重要程度最低的三个变量分别是“薪资水平”、“完成项目的数量”和“是否在IT/IS部门”。这三个变量与员工个人的性格、工作能力、家庭关系较小，属于对工作分类的刻画，对于预测员工是否离职的重要性较低。

## SVM

Logit、LDA、PLSDA 本质上都是线性模型，即模型结构产生线性类边界，这一类模型的优点是不太会受到无信息变量的干扰。然而，在我们的数据中，并没有存在大量无信息变量的情况，所以我们考虑使用非线性模型进行训练。

```{r}
set.seed(1)
svm <- train(Terminate ~ Sex + MaritalDesc + Department + PerformanceScore + EngagementSurvey + EmpSatisfaction + SpecialProjectsCount + PayRate, data = training, 
                 method = "svmRadial", 
                 trControl = fitControl,
            tuneLength = 5)
kable(svm$results, caption = "在重抽样下 SVM 模型的表现", digits = 3)
```

```{r fig.align="center", fig.cap="调优参数不同取值下的准确率和 Kappa 指标变化", out.width="49%", fig.show='hold'}
trellis.par.set(caretTheme())
plot(svm)
plot(svm, metric = "Kappa")
```

## 随机梯度助推法（GBM）

第三类被广泛应用的模型是分类树与基于规则的模型，在此，我们使用助推法这种树结构与规则的融合方法。

Friedman等（2000） @Ben2000Tissue 发现分类问题可以当作是正向分布可加模型，通过最小化指数损失函数实现分类。

首先我们设定样本预测初始值为对数发生：

$$
f_{i}^{(0)}=\log \frac{\hat{p}}{1-\hat{p}}
$$

其中，$f(x)$ 是模型的预测值，$\hat{p}_{i}=\frac{1}{1+\exp [-f(x)]}$

接着从 $j = 1$ 开始进行迭代：

1. 计算梯度 $z_{i}=y_{i}-\hat{p}_{i}$
2. 对训练集随机抽样
3. 基于子样本，用之前得到的残差作为结果变量训练树模型
4. 计算终结点 Pearson 残差的估计 $r_{i}=\frac{1 / n\sum_{i}^{n}\left(y_{i}-\hat{p}_{i}\right)}{1 / n \sum_{i}^{n} \hat{p}_{i}\left(1-\hat{p}_{i}\right)}$
5. 更新当前模型 $f_{1}=f_{i}+\lambda f_{i}^{(j)}$

```{r include=FALSE}
set.seed(1)
gbm <- train(Terminate ~ Sex + MaritalDesc + Department + PerformanceScore + EngagementSurvey + EmpSatisfaction + SpecialProjectsCount + PayRate, data = training, 
                 method = "gbm", 
                 trControl = fitControl)
kable(gbm$results, caption = "在重抽样下 GBM 模型的表现", digits = 3)
```

```{r fig.align="center", fig.cap="调优参数和迭代次数不同取值下的准确率和 Kappa 指标变化", out.width="49%", fig.show='hold'}
trellis.par.set(caretTheme())
plot(gbm)

trellis.par.set(caretTheme())
plot(gbm, metric = "Kappa")
```

助推树的加深和迭代次数的增多一般引起 Kappa 指标的上升，随着迭代次数的增加，准确率变动先下降后上升。

```{r fig.align="center", fig.cap="在重抽样下 GBM 模型的准确率分布", out.width="50%"}
trellis.par.set(caretTheme())
densityplot(gbm, pch = "|")
```

## 模型间的比较

我们对训练的4个不同的模型进行比较，所有模型都使用相同的重抽样方法估计各自的模型表现。且由于设置的随机数种子相同，故不同模型使用的重抽样样本完全一致。 ^[重抽样 50 次：10 折交叉验证重复 5 次]

```{r}
resamp = resamples(list(LDA = lda, PLSDA = plsda, SVM = svm, GBM = gbm, Logit = logit))
s1 = summary(resamp)
s2 = summary(diff(resamp))
```

```{r fig.align="center", fig.cap="模型间 Kappa 的比较（0.95 置信区间）", out.width="80%", fig.height=3, fig.width=6}
ggplot(resamp,
       models = c("LDA", "PLSDA", "GBM", "Logit"),
       metric = "Kappa",
       conf.level = 0.95) +
  theme_bw()
```

```{r fig.align="center", fig.cap="模型间准确率的比较（0.95 置信区间）", out.width="80%", fig.height=3, fig.width=6}
ggplot(resamp,
       models = c("LDA", "PLSDA", "SVM", "GBM", "Logit"),
       metric = "Accuracy",
       conf.level = 0.95) +
  theme_bw()
```

\newpage

# 结论

---

在此研究中，我们主要研究了XXXXXXXXX。

---

## 阈值选择

结合具体的业务，为了达到最高的效率，我们可以通过**确定不同的预测阈值来达到不同的效果**，例如：

1. 在进行交易风控、信用卡降额的自动化系统构建时，通过确定较高的阈值以提高特异度，避免错判。
2. 在进行逾期自动化预测以便于进一步调查时，通过降低阈值的方式提高灵敏度，以检测出更多潜在逾期持卡人。
3. 通过平衡错判的成本与查漏的损失，确定适中的阈值以谋求商业利益最大化。

## 模型选择

在**准确率**这一效果衡量指标下，从偏差的角度来看，GBM 有着最好的效果，Logit 模型次之；从方差的角度来看，PLSDA 和 SVM 模型具有明显较小的方差；LDA 模型则表现不佳。

综合来看，**GBM**模型具有最好的效果，**Logit**模型次之。然而，在模型的应用方面，我们更加倾向于使用计算速度较快、可解释性强的 Logit 模型。

## 变量选择

根据 PLSDA 的结果，数据集中最重要的变量描述的是持卡人过去是否有信用卡逾期的先例，它们很好地反映出借贷者的信誉情况。过去出现过逾期的先例，那么未来信用卡逾期的可能性就大大增加。

而重要程度最低的三个变量分别是“家属人数”“负债比率”和“月收入”。这三个变量与个人信誉的关系不大，属于外界因素。即使家属人数多，负债比率高，月收入低，持卡人依旧可以通过合理规划及时还款。即这些变量并不直接反应持卡人的还贷习惯，影响较低。

\newpage

# 参考文献

<div id="refs"></div>

\newpage

# 附录

## 模型间准确率和 Kappa 的比较

```{r}
kable(s1$statistics$Accuracy, caption = "模型间准确率的比较", digit = 3)
```

```{r}
kable(s2$table$Accuracy, caption = "模型间准确率差异矩阵", digit = 3)
```

```{r}
kable(s1$statistics$Kappa, caption = "模型间 Kappa 的比较", digit = 3)
```

```{r}
kable(s2$table$Accuracy, caption = "模型间Kappa差异矩阵", digit = 3)
```

## Logit 回归结果

```{r}
logit2_sum
```

## 数据

```{r}
str(dat)
```

```{r}
summary(dat)
```



